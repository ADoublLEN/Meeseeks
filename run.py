#!/usr/bin/env python3
"""
OG_meeseeksé¡¹ç›®çš„ä¸»è¿è¡Œæ–‡ä»¶
æ›¿ä»£evaluate.pyçš„é€»è¾‘ï¼Œæ”¯æŒå‚æ•°åŒ–é…ç½®
"""

import sys
import subprocess
import os

def install_requirements():
    """è‡ªåŠ¨å®‰è£…requirements.txtä¸­çš„ä¾èµ–åŒ…"""
    requirements_file = os.path.join(os.path.dirname(__file__), 'requirements.txt')

    if os.path.exists(requirements_file):
        print("ğŸ”§ Checking and installing dependencies...")
        try:
            # è¯»å–requirements.txt
            with open(requirements_file, 'r', encoding='utf-8') as f:
                requirements = f.readlines()

            # è¿‡æ»¤æ‰æ³¨é‡Šå’Œç©ºè¡Œ
            packages = []
            for line in requirements:
                line = line.strip()
                if line and not line.startswith('#'):
                    packages.append(line)

            if packages:
                print(f"ğŸ“¦ Found {len(packages)} dependencies to check...")
                for package in packages:
                    print(f"   - {package}")

                # å®‰è£…ä¾èµ–
                subprocess.check_call([
                    sys.executable, "-m", "pip", "install", "-r", requirements_file
                ])
                print("âœ… All dependencies installed successfully!")
            else:
                print("ğŸ“¦ No dependencies found to install")

        except subprocess.CalledProcessError as e:
            print(f"âŒ Error installing dependencies: {e}")
            print("Please run manually: pip install -r requirements.txt")
        except Exception as e:
            print(f"âŒ Error reading requirements.txt: {e}")
    else:
        print("âš ï¸  requirements.txt file not found")

def fix_json_data(data):
    new_data = []
    for item in data:
        flag = 1 if iferror(item) else 0
        if "json_schema" in item or "SCHEMA" in item:
            og_subqs = [
                {
                    "point_id": 0,
                    "question": "Does it meet schema requirements",
                    "rule": "SCHEMA:json_schema",
                    "eval_result": flag,
                    "dep": [],
                    "è¢«ä¾èµ–": False,
                    "èƒ½åŠ›é¡¹": "JSON"
                }]
            for subq in item["sub_questions"]:
                if subq["point_id"] > 0:
                    og_subqs.append(subq)
            item["sub_questions"] = og_subqs
        new_data.append(item)

    return new_data

# åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰å…ˆå®‰è£…ä¾èµ–
if __name__ == "__main__":
    install_requirements()

import json
import time
import argparse
import requests
import sys
import os

# æ·»åŠ src_codeç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src_code'))

from process_corresponding_parts import extract_content
from process_evaluation import process_all_items
from multi_round_template_added import multi_round_template_added
from LLM_APIs.qwen_api import set_qwen_url
from LLM_APIs.qwen_coder_api import set_qwen_coder_url
from LLM_APIs.tested_model_api import set_tested_model_url, call_tested_model
from final_stats import calculate_and_save_stats


def get_language_modules(language):
    """æ ¹æ®è¯­è¨€å‚æ•°åŠ¨æ€å¯¼å…¥ç›¸åº”çš„æ¨¡å—"""
    if language == 'english':
        # å¯¼å…¥è‹±æ–‡ç‰ˆæœ¬çš„æ¨¡å—
        from process_rule_based_evaluate_eng import rule_based_evaluate
        return rule_based_evaluate
    else:
        # é»˜è®¤ä½¿ç”¨ä¸­æ–‡ç‰ˆæœ¬çš„æ¨¡å—
        from process_rule_based_evaluate import rule_based_evaluate
        return rule_based_evaluate


def test_single_api(url, api_name, test_prompt="Hello"):
    """æµ‹è¯•å•ä¸ªAPIæ˜¯å¦å¯ç”¨"""
    print(f"ğŸ”— Testing {api_name}: {url}")

    payload = {
        "prompt": test_prompt,
        "max_new_tokens": 50,
        "temperature": 0.00,
        "top_k": 1
    }
    headers = {
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=1800)

        if response.status_code == 200:
            try:
                response_json = response.json()
                if 'completions' in response_json and response_json['completions']:
                    print(f"âœ… {api_name} is working")
                    return True
                else:
                    print(f"âŒ {api_name} returned invalid format")
                    return False
            except json.JSONDecodeError:
                print(f"âŒ {api_name} returned non-JSON response")
                return False
        else:
            print(f"âŒ {api_name} returned HTTP {response.status_code}")
            return False

    except requests.exceptions.ConnectionError:
        print(f"âŒ {api_name} connection failed")
        return False
    except requests.exceptions.Timeout:
        print(f"âŒ {api_name} timeout")
        return False
    except Exception as e:
        print(f"âŒ {api_name} error: {e}")
        return False


def test_all_apis(qwen_url, qwen_coder_url, tested_model_url):
    """æµ‹è¯•æ‰€æœ‰ä¸‰ä¸ªAPIæ˜¯å¦å¯ç”¨"""
    print("ğŸ§ª Testing API connections...")
    print("=" * 50)

    results = {}
    results['qwen'] = test_single_api(qwen_url, "Qwen API")
    results['qwen_coder'] = test_single_api(qwen_coder_url, "Qwen Coder API")
    results['tested_model'] = test_single_api(tested_model_url, "Tested Model API")

    print("=" * 50)

    all_working = all(results.values())
    if all_working:
        print("âœ… All APIs are working properly!")
        return True
    else:
        print("âŒ Some APIs are not working:")
        for api_name, status in results.items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"   {status_icon} {api_name}: {'Working' if status else 'Failed'}")

        print("\nğŸ’¡ Please check:")
        print("   - API services are running")
        print("   - URLs are correct")
        print("   - Network connectivity")
        print("   - Firewall settings")

        user_input = input("\nâ“ Continue anyway? (y/N): ").strip().lower()
        return user_input in ['y', 'yes']


def process_in_batches(data, batch_size=100):
    """æ‰¹é‡å¤„ç†æ•°æ®ï¼Œè°ƒç”¨è¢«æµ‹æ¨¡å‹è·å–å“åº”"""
    total_items = len(data)
    for batch_start in range(0, total_items, batch_size):
        batch_end = min(batch_start + batch_size, total_items)
        current_batch = data[batch_start:batch_end]

        # Print processing progress
        print(f"ğŸ“Š Processing items {batch_start}-{batch_end-1} out of {total_items} total items...")

        try:
            # Batch get questions and call model
            batch_questions = [item["question"] for item in current_batch]
            batch_responses = call_tested_model(batch_questions)  # ä½¿ç”¨è¢«æµ‹æ¨¡å‹

            # Assign responses back to data items
            for item, response in zip(current_batch, batch_responses):
                item["model_response"] = response

        except Exception as e:
            print(f"âŒ Error occurred while processing batch {batch_start}-{batch_end-1}: {str(e)}")
            # Add retry logic or error handling here


def iferror(item):
    """æ£€æŸ¥æ˜¯å¦æœ‰è¯„ä¼°é”™è¯¯"""
    for subq in item["sub_questions"]:
        if subq["eval_result"] == 0:
            return True
    return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='OG_meeseeksè¯„ä¼°ç³»ç»Ÿ')
    parser.add_argument('--qwen_url', required=True, help='Qwen APIçš„URL')
    parser.add_argument('--qwen_coder_url', required=True, help='Qwen Coder APIçš„URL')
    parser.add_argument('--tested_model_url', required=True, help='è¢«æµ‹æ¨¡å‹APIçš„URL')
    parser.add_argument('--batch_size', type=int, default=100, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--rounds', type=int, default=2, help='è¯„ä¼°è½®æ•°')
    parser.add_argument('--output_dir', default='evaluation_results', help='è¾“å‡ºç›®å½•')

    # åˆ›å»ºäº’æ–¥ç»„ï¼šlanguage å’Œ data_path åªèƒ½é€‰æ‹©ä¸€ä¸ª
    data_group = parser.add_mutually_exclusive_group(required=True)
    data_group.add_argument('--language', choices=['chinese', 'english'],
                           help='é€‰æ‹©è¯­è¨€æ•°æ®é›†ï¼šchinese æˆ– english')
    data_group.add_argument('--data_path', help='è‡ªå®šä¹‰æ•°æ®æ–‡ä»¶è·¯å¾„')



    args = parser.parse_args()

    # è®¾ç½®API URLs
    set_qwen_url(args.qwen_url)
    set_qwen_coder_url(args.qwen_coder_url)
    set_tested_model_url(args.tested_model_url)

    # æµ‹è¯•APIè¿æ¥
    if not test_all_apis(args.qwen_url, args.qwen_coder_url, args.tested_model_url):
        print("ğŸ›‘ API test failed, program exiting")
        return

    print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)

    # å¤„ç†æ•°æ®è·¯å¾„
    if args.language:
        # æ ¹æ®è¯­è¨€å‚æ•°ç¡®å®šæ•°æ®ç›®å½•
        if args.language == 'chinese':
            data_dir = os.path.join(os.path.dirname(__file__), 'input_data', 'chinese_data', 'raw_input')
        else:  # english
            data_dir = os.path.join(os.path.dirname(__file__), 'input_data', 'english_data', 'raw_input')

        print(f"ğŸ“‚ Loading {args.language} data from directory: {data_dir}")

        # è·å–ç›®å½•ä¸­æ‰€æœ‰JSONæ–‡ä»¶
        json_files = [f for f in os.listdir(data_dir) if f.endswith('.json')]
        if not json_files:
            print(f"âŒ No JSON files found in {data_dir}")
            return

        print(f"ğŸ“„ Found {len(json_files)} JSON files:")
        for file in json_files:
            print(f"   - {file}")

        # åˆå¹¶æ‰€æœ‰JSONæ–‡ä»¶çš„æ•°æ®
        current_data = []
        for json_file in json_files:
            file_path = os.path.join(data_dir, json_file)
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    file_data = json.load(f)
                    if isinstance(file_data, list):
                        current_data.extend(file_data)
                    else:
                        current_data.append(file_data)
                print(f"âœ… Loaded {json_file}")
            except Exception as e:
                print(f"âŒ Error loading {json_file}: {e}")
    else:
        # ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®è·¯å¾„
        print(f"ğŸ“‚ Loading data from: {args.data_path}")
        with open(args.data_path, "r", encoding="utf-8") as f:
            current_data = json.load(f)

    # ä¿å­˜åŸå§‹é—®é¢˜
    for item in current_data:
        item["og_question"] = item["question"]

    print(f"ğŸ“Š Loaded {len(current_data)} items")
    print(f"ğŸ”§ Configuration:")
    print(f"   - Qwen URL: {args.qwen_url}")
    print(f"   - Qwen Coder URL: {args.qwen_coder_url}")
    print(f"   - Tested Model URL: {args.tested_model_url}")
    print(f"   - Batch Size: {args.batch_size}")
    print(f"   - Rounds: {args.rounds}")
    if args.language:
        print(f"   - Language: {args.language}")
        print(f"   - Data Directory: {data_dir}")
    else:
        print(f"   - Data Path: {args.data_path}")
    print(f"   - Output Directory: {args.output_dir}")
    print("=" * 80)

    # æ ¹æ®è¯­è¨€å‚æ•°è·å–ç›¸åº”çš„è¯„ä¼°å‡½æ•°
    rule_based_evaluate_func = get_language_modules(args.language if args.language else 'chinese')
    print(f"ğŸ”§ğŸ”§ğŸ”§ Using {'English' if args.language == 'english' else 'Chinese'} evaluation modules")

    # å¤šè½®è¯„ä¼°
    all_data = current_data.copy()  # ä¿å­˜æ‰€æœ‰æ•°æ®çš„å‰¯æœ¬

    for round_num in range(args.rounds):
        print(f"ğŸš€ Starting Round {round_num + 1} Evaluation")
        print("=" * 60)

        # ç¬¬ä¸€è½®ä¹‹åï¼Œåªå¯¹æœ‰é”™è¯¯çš„é¡¹ç›®é‡æ–°è¯„ä¼°ï¼Œä½†ä¿ç•™æ‰€æœ‰æ•°æ®
        if round_num != 0:
            # æ‰¾å‡ºéœ€è¦é‡æ–°è¯„ä¼°çš„é¡¹ç›®ï¼ˆä»all_dataä¸­æŸ¥æ‰¾ï¼‰
            items_to_reevaluate = [item for item in all_data if iferror(item)]
            if not items_to_reevaluate:
                print("âœ… No items to re-evaluate in this round. All evaluations passed!")
                # ä»ç„¶ä¿å­˜å®Œæ•´ç»“æœ
                output_file = os.path.join(args.output_dir, f"round_{round_num + 1}.json")
                with open(output_file, "w", encoding="utf-8") as f:
                    json.dump(all_data, f, ensure_ascii=False, indent=4)
                print(f"ğŸ’¾ Complete results saved to: {output_file}")
                break

            # å¯¹éœ€è¦é‡æ–°è¯„ä¼°çš„é¡¹ç›®åº”ç”¨å¤šè½®æ¨¡æ¿
            items_to_reevaluate = multi_round_template_added(items_to_reevaluate)
            items_to_reevaluate = fix_json_data(items_to_reevaluate)
            print(f"ğŸ“Š Re-evaluating {len(items_to_reevaluate)} items with errors from previous round")

            # è®¾ç½®å½“å‰å¤„ç†çš„æ•°æ®ä¸ºéœ€è¦é‡æ–°è¯„ä¼°çš„é¡¹ç›®
            current_data = items_to_reevaluate
        else:
            print(f"ğŸ“Š Processing {len(current_data)} items in first round")

        if not current_data:
            print("âœ… No items to process in this round!")
            break

        # å¤„ç†model_responseæ”¶é›†
        print("ğŸ“ Getting model responses for evaluation...")
        process_in_batches(current_data, args.batch_size)

        # å¼€å§‹è¯„ä¼°
        og_start_time = time.time()
        print(f"ğŸ”„ Round {round_num + 1} Processing Started")

        # æ­¥éª¤1ï¼šæå–å¯¹åº”éƒ¨åˆ†
        start_time = time.time()
        print("ğŸ” Step 1: Extracting corresponding parts from all responses...")
        current_data = extract_content(current_data, args.batch_size)
        print("âœ… Corresponding parts extraction completed successfully")
        end_time = time.time()
        print(f"â±ï¸  Time taken: {end_time - start_time:.2f} seconds")
        print()

        # æ­¥éª¤2ï¼šå¤„ç†å’Œè¯„ä¼°
        start_time = time.time()
        print("ğŸ” Step 2: Processing and evaluating all items...")
        current_data = process_all_items(current_data, args.batch_size, rule_based_evaluate_func)
        print("âœ… Item processing and evaluation completed successfully")
        end_time = time.time()
        print(f"â±ï¸  Time taken: {end_time - start_time:.2f} seconds")
        print()

        total_time = end_time - og_start_time
        print("=" * 60)
        print(f"ğŸ‰ Round {round_num + 1} Completed Successfully!")
        print(f"â±ï¸  Total round time: {total_time:.2f} seconds")
        print("=" * 60)

        # ä¿å­˜ç»“æœ
        if round_num == 0:
            # ç¬¬ä¸€è½®ï¼šæ›´æ–°all_dataä¸ºå½“å‰è¯„ä¼°ç»“æœ
            all_data = current_data.copy()
            output_file = os.path.join(args.output_dir, f"round_{round_num + 1}.json")
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(all_data, f, ensure_ascii=False, indent=4)
            print(f"ğŸ’¾ Results saved to: {output_file}")
        else:
            # åç»­è½®æ¬¡ï¼šåˆå¹¶ç»“æœï¼Œç”¨é‡æ–°è¯„ä¼°çš„ç»“æœæ›´æ–°å¯¹åº”é¡¹ç›®
            # ä½¿ç”¨åŸå§‹é—®é¢˜ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦æ¥åŒ¹é…é¡¹ç›®
            reevaluated_items = {item.get('og_question', item.get('question', '')): item for item in current_data}

            # æ›´æ–°all_dataä¸­å¯¹åº”çš„é¡¹ç›®
            for i, item in enumerate(all_data):
                item_key = item.get('og_question', item.get('question', ''))
                if item_key in reevaluated_items:
                    all_data[i] = reevaluated_items[item_key]

            output_file = os.path.join(args.output_dir, f"round_{round_num + 1}.json")
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(all_data, f, ensure_ascii=False, indent=4)
            print(f"ğŸ’¾ Complete results (including previous rounds) saved to: {output_file}")

        # è®¡ç®—å¹¶ä¿å­˜ç»Ÿè®¡ç»“æœ
        try:
            # ç¡®å®šè¯­è¨€å‚æ•°
            language = args.language if args.language else 'chinese'
            calculate_and_save_stats(output_file, round_num + 1, args.output_dir, language)
        except Exception as e:
            print(f"âš ï¸  Warning: Failed to calculate statistics for round {round_num + 1}: {e}")

        print()


    print("ğŸŠ All rounds completed successfully!")


if __name__ == "__main__":
    main()
